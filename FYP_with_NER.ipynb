{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c7ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the Excel file and read the first sheet into a DataFrame\n",
    "df = pd.read_excel(r'Dataset.xlsx', sheet_name=0, usecols='A:E', header=None)\n",
    "\n",
    "# Concatenate all the columns into a single column\n",
    "df = pd.DataFrame(df.apply(lambda x: ''.join(x.dropna().astype(str)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b91f466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     data\n",
      "0       item_type\\titem_urn\\tcontent\\tinstrument_name\\...\n",
      "1       conditional\\turn:ddi:uk.lha:bc358498-7085-4422...\n",
      "2       conditional\\turn:ddi:uk.lha:b7ec8f60-a0b7-4dbb...\n",
      "3       codelist\\turn:ddi:uk.lha:bdb9ae15-1848-41d7-8e...\n",
      "4       codelist\\turn:ddi:uk.lha:5fc4c7c5-2713-4d76-80...\n",
      "...                                                   ...\n",
      "186255  statement\\turn:ddi:uk.lha:7817cb4c-99da-4676-a...\n",
      "186256  instruction\\turn:ddi:uk.lha:ba7dfd64-72ff-4988...\n",
      "186257  instruction\\turn:ddi:uk.lha:c93e8e55-26d3-474f...\n",
      "186258  instruction\\turn:ddi:uk.lha:ebf4e882-9fac-4a72...\n",
      "186259  instruction\\turn:ddi:uk.lha:ff7a6892-04af-4c41...\n",
      "\n",
      "[186260 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "first_col = df.columns[0]\n",
    "df.rename(columns={first_col: 'data'}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4218b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          item_type                                            content\n",
      "0       conditional  and then go straight on to Question 8]qc_1_i =...\n",
      "1       conditional                         \"[If \"\"YES\"\"]qc_21_a == 1\"\n",
      "2          codelist                                   1 a club at work\n",
      "3          codelist                           2 an outside sports club\n",
      "4          codelist                             3 you and your friends\n",
      "...             ...                                                ...\n",
      "141022    statement  (N.B. By friends we mean people who you meet o...\n",
      "141023  instruction                Please tick the appropriate column.\n",
      "141024  instruction               (PLEASE TICK THE APPROPRIATE COLUMN)\n",
      "141025  instruction         (Circle more than one number if necessary)\n",
      "141026  instruction         (If necessary circle more than one number)\n",
      "\n",
      "[141027 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "rows = []\n",
    "for index, row in df.iloc[1:].iterrows():\n",
    "    words = re.split(r\"\\s{2,}\", row[0])\n",
    "    new_list = [item.split('\\t') for item in words]\n",
    "    if len(new_list[0]) == 5:\n",
    "        rows.append({'item_type': new_list[0][0], 'content': new_list[0][2]})\n",
    "\n",
    "new_df = pd.DataFrame(rows)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c67957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27408874",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['content']=new_df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e82f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['item_type']=new_df['item_type'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e30e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_type', 'content'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c202a36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          item_type                                            content  \\\n",
      "0       conditional  and then go straight on to question 8]qc_1_i =...   \n",
      "1       conditional                         \"[if \"\"yes\"\"]qc_21_a == 1\"   \n",
      "2          codelist                                   1 a club at work   \n",
      "3          codelist                           2 an outside sports club   \n",
      "4          codelist                             3 you and your friends   \n",
      "...             ...                                                ...   \n",
      "141022    statement  (n.b. by friends we mean people who you meet o...   \n",
      "141023  instruction                please tick the appropriate column.   \n",
      "141024  instruction               (please tick the appropriate column)   \n",
      "141025  instruction         (circle more than one number if necessary)   \n",
      "141026  instruction         (if necessary circle more than one number)   \n",
      "\n",
      "        item_type_id  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  1  \n",
      "3                  1  \n",
      "4                  1  \n",
      "...              ...  \n",
      "141022             3  \n",
      "141023             4  \n",
      "141024             4  \n",
      "141025             4  \n",
      "141026             4  \n",
      "\n",
      "[141027 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4a513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print (type(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd0aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687f403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((str(ent.text), str(ent.label_)))\n",
    "    return entities\n",
    "new_df = new_df.astype(str)\n",
    "\n",
    "new_df['entities'] = new_df['content'].apply(extract_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b3cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORDINAL', 'TIME', 'GPE', 'MONEY', 'FAC', 'CARDINAL', 'LAW', 'PERSON', 'DATE', 'PERCENT', 'LOC', 'QUANTITY', 'PRODUCT', 'NORP', 'EVENT', 'WORK_OF_ART', 'LANGUAGE', 'ORG'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "\n",
    "for entities in new_df['entities']:\n",
    "    try:\n",
    "        unique_labels.update([entity[1] for entity in entities])\n",
    "    except TypeError:\n",
    "        continue\n",
    "\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86df2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def choose_entity_label(entities):\n",
    "    if not entities:\n",
    "        return 'none'\n",
    "    else:\n",
    "        return random.choice(entities)[1]\n",
    "\n",
    "new_df['entities_label'] = new_df['entities'].apply(choose_entity_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9405bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(new_df.shape[0]*0.8)\n",
    "train_new_df = new_df[:train_size]\n",
    "val_df = new_df[train_size:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79fa2e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4408/4408 [==============================] - 543s 122ms/step - loss: 0.7558 - accuracy: 0.7776\n",
      "Epoch 2/5\n",
      "4408/4408 [==============================] - 632s 143ms/step - loss: 0.6780 - accuracy: 0.8003\n",
      "Epoch 3/5\n",
      "4408/4408 [==============================] - 630s 143ms/step - loss: 0.6751 - accuracy: 0.8005\n",
      "Epoch 4/5\n",
      "4408/4408 [==============================] - 648s 147ms/step - loss: 0.6791 - accuracy: 0.7991\n",
      "Epoch 5/5\n",
      "4408/4408 [==============================] - 684s 155ms/step - loss: 0.6767 - accuracy: 0.8012\n",
      "Epoch 1/5\n",
      "3526/3526 [==============================] - 436s 124ms/step - loss: 0.6727 - accuracy: 0.8020 - val_loss: 0.6900 - val_accuracy: 0.7962\n",
      "Epoch 2/5\n",
      "3526/3526 [==============================] - 439s 125ms/step - loss: 0.6724 - accuracy: 0.8019 - val_loss: 0.6913 - val_accuracy: 0.7959\n",
      "Epoch 3/5\n",
      "3526/3526 [==============================] - 437s 124ms/step - loss: 0.6722 - accuracy: 0.8022 - val_loss: 0.6867 - val_accuracy: 0.7949\n",
      "Epoch 4/5\n",
      "3526/3526 [==============================] - 409s 116ms/step - loss: 0.6722 - accuracy: 0.8018 - val_loss: 0.6924 - val_accuracy: 0.7972\n",
      "Epoch 5/5\n",
      "3526/3526 [==============================] - 386s 109ms/step - loss: 0.6718 - accuracy: 0.8023 - val_loss: 0.6866 - val_accuracy: 0.7972\n"
     ]
    }
   ],
   "source": [
    "#LSTM With NER\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "item_type_dict = {item_typ: i for i, item_typ in enumerate(new_df['item_type'].unique())}\n",
    "new_df['item_type_id'] = new_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(new_df['content'])\n",
    "sequences = tokenizer.texts_to_sequences(new_df['content'])\n",
    "\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(new_df['entities_label'])\n",
    "label_sequences = label_tokenizer.texts_to_sequences(new_df['entities_label'])\n",
    "\n",
    "max_label_length = max(len(seq) for seq in label_sequences)\n",
    "padded_label_sequences = pad_sequences(label_sequences, maxlen=max_label_length, padding='post')\n",
    "\n",
    "labels = to_categorical(new_df['item_type_id'])\n",
    "\n",
    "# Define the model architecture\n",
    "embedding_dim = 50\n",
    "\n",
    "content_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length)\n",
    "embedded_sequences = embedding_layer(content_input)\n",
    "lstm_layer = LSTM(50)(embedded_sequences)\n",
    "\n",
    "label_input = Input(shape=(max_label_length,))\n",
    "label_embedding_layer = Embedding(input_dim=len(label_tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_label_length)\n",
    "embedded_label_sequences = label_embedding_layer(label_input)\n",
    "lstm_label_layer = LSTM(50)(embedded_label_sequences)\n",
    "\n",
    "merged = concatenate([lstm_layer, lstm_label_layer])\n",
    "dense_layer = Dense(10, activation='relu')(merged)\n",
    "output_layer = Dense(len(item_type_dict), activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=[content_input, label_input], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([padded_sequences, padded_label_sequences], labels, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Get the predicted labels and ground truth labels for the validation set\n",
    "val_padded_sequences = padded_sequences[int(len(padded_sequences)*0.8):]\n",
    "val_padded_label_sequences = padded_label_sequences[int(len(padded_label_sequences)*0.8):]\n",
    "val_labels = labels[int(len(labels)*0.8):]\n",
    "\n",
    "val_pred_probs = model.predict([val_padded_sequences, val_padded_label_sequences])\n",
    "val_pred_labels = val_pred_probs.argmax(axis=1)\n",
    "val_true_labels = val_labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "832a05e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " conditional       0.65      0.02      0.04      1614\n",
      "    codelist       0.85      0.92      0.88     16105\n",
      "    question       0.72      0.91      0.80      8414\n",
      "   statement       0.70      0.00      0.01      1601\n",
      " instruction       0.00      0.00      0.00       431\n",
      "        loop       0.00      0.00      0.00        40\n",
      "                   0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80     28206\n",
      "   macro avg       0.42      0.27      0.25     28206\n",
      "weighted avg       0.77      0.80      0.75     28206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Compute evaluation metrics\n",
    "report = classification_report(val_true_labels, val_pred_labels, target_names=item_type_dict.keys())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b14e918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - 22s 24ms/step - loss: 0.6877 - accuracy: 0.7969\n",
      "Validation loss: 0.6876544952392578\n",
      "Validation accuracy: 0.7968871593475342\n",
      "Confusion matrix:\n",
      " [[   38  1351   225     0     0     0     0]\n",
      " [   15 14666  1421     3     0     0     0]\n",
      " [    0   641  7772     1     0     0     0]\n",
      " [    2   328  1270     1     0     0     0]\n",
      " [    0   142   289     0     0     0     0]\n",
      " [    0    25    14     1     0     0     0]\n",
      " [    0     0     1     0     0     0     0]]\n",
      "Class names: ['conditional', 'codelist', 'question', 'statement', 'instruction', 'loop', '']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "val_df['item_type_id'] = val_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df['content'])\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "val_label_sequences = label_tokenizer.texts_to_sequences(val_df['entities_label'])\n",
    "val_padded_label_sequences = pad_sequences(val_label_sequences, maxlen=max_label_length, padding='post')\n",
    "\n",
    "val_labels = to_categorical(val_df['item_type_id'])\n",
    "\n",
    "loss, accuracy = model.evaluate([val_padded_sequences, val_padded_label_sequences], val_labels)\n",
    "print(\"Validation loss:\", loss)\n",
    "print(\"Validation accuracy:\", accuracy)\n",
    "\n",
    "predicted_labels = model.predict([val_padded_sequences, val_padded_label_sequences])\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "class_names = list(item_type_dict.keys())\n",
    "true_labels = val_df['item_type_id']\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=list(item_type_dict.values()))\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training BiLSTM with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e113c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3705d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4408/4408 [==============================] - 393s 88ms/step - loss: 0.2976 - accuracy: 0.9114\n",
      "Epoch 2/2\n",
      "4408/4408 [==============================] - 435s 99ms/step - loss: 0.0511 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2448484b5c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length)(content_input)\n",
    "lstm_layer = Bidirectional(LSTM(20))(embedding_layer)\n",
    "\n",
    "label_input = Input(shape=(max_label_length,))\n",
    "label_embedding_layer = Embedding(input_dim=len(label_tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_label_length)(label_input)\n",
    "lstm_label_layer = Bidirectional(LSTM(20))(label_embedding_layer)\n",
    "\n",
    "merged = concatenate([lstm_layer, lstm_label_layer])\n",
    "dense_layer = Dense(10, activation='relu')(merged)\n",
    "output_layer = Dense(len(item_type_dict), activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=[content_input, label_input], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit([padded_sequences, padded_label_sequences], labels, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b6610f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - 17s 18ms/step - loss: 0.0324 - accuracy: 0.9911\n",
      "Validation loss: 0.032366495579481125\n",
      "Validation accuracy: 0.9911366105079651\n",
      "Confusion matrix:\n",
      " [[ 1597     0     8     4     3     2     0]\n",
      " [    1 16094     3     4     3     0     0]\n",
      " [    2     6  8323    54    29     0     0]\n",
      " [    7     9    47  1507    30     1     0]\n",
      " [    3     1    14    15   398     0     0]\n",
      " [    0     2     1     0     0    37     0]\n",
      " [    0     0     0     1     0     0     0]]\n",
      "Class names: ['conditional', 'codelist', 'question', 'statement', 'instruction', 'loop', '']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "val_df['item_type_id'] = val_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df['content'])\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "val_label_sequences = label_tokenizer.texts_to_sequences(val_df['entities_label'])\n",
    "val_padded_label_sequences = pad_sequences(val_label_sequences, maxlen=max_label_length, padding='post')\n",
    "\n",
    "val_labels = to_categorical(val_df['item_type_id'])\n",
    "\n",
    "loss, accuracy = model.evaluate([val_padded_sequences, val_padded_label_sequences], val_labels)\n",
    "print(\"Validation loss:\", loss)\n",
    "print(\"Validation accuracy:\", accuracy)\n",
    "\n",
    "predicted_labels = model.predict([val_padded_sequences, val_padded_label_sequences])\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "class_names = list(item_type_dict.keys())\n",
    "true_labels = val_df['item_type_id']\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=list(item_type_dict.values()))\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f879e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " conditional       0.99      0.99      0.99      1614\n",
      "    codelist       1.00      1.00      1.00     16105\n",
      "    question       0.99      0.99      0.99      8414\n",
      "   statement       0.95      0.94      0.95      1601\n",
      " instruction       0.86      0.92      0.89       431\n",
      "        loop       0.93      0.93      0.93        40\n",
      "                   0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99     28206\n",
      "   macro avg       0.82      0.82      0.82     28206\n",
      "weighted avg       0.99      0.99      0.99     28206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the class names\n",
    "class_names = list(item_type_dict.keys())\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21195d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
