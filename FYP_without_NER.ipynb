{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33beb4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3526/3526 [==============================] - 310s 87ms/step - loss: 1.1078 - accuracy: 0.5872 - val_loss: 1.0853 - val_accuracy: 0.5710\n",
      "Epoch 2/5\n",
      "3526/3526 [==============================] - 349s 99ms/step - loss: 1.0671 - accuracy: 0.5989 - val_loss: 1.0856 - val_accuracy: 0.5710\n",
      "Epoch 3/5\n",
      "3526/3526 [==============================] - 393s 111ms/step - loss: 1.0651 - accuracy: 0.6005 - val_loss: 1.0885 - val_accuracy: 0.5710\n",
      "Epoch 4/5\n",
      "3526/3526 [==============================] - 414s 117ms/step - loss: 1.0643 - accuracy: 0.5990 - val_loss: 1.0899 - val_accuracy: 0.5710\n",
      "Epoch 5/5\n",
      "3526/3526 [==============================] - 414s 117ms/step - loss: 1.0669 - accuracy: 0.5982 - val_loss: 1.0851 - val_accuracy: 0.5710\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the Excel file and read the first sheet into a DataFrame\n",
    "df = pd.read_excel(r'Dataset.xlsx', sheet_name=0, usecols='A:E', header=None)\n",
    "\n",
    "# Concatenate all the columns into a single column\n",
    "df = pd.DataFrame(df.apply(lambda x: ''.join(x.dropna().astype(str)), axis=1))\n",
    "\n",
    "first_col = df.columns[0]\n",
    "df.rename(columns={first_col: 'data'}, inplace=True)\n",
    "\n",
    "import re\n",
    "rows = []\n",
    "for index, row in df.iloc[1:].iterrows():\n",
    "    words = re.split(r\"\\s{2,}\", row[0])\n",
    "    new_list = [item.split('\\t') for item in words]\n",
    "    if len(new_list[0]) == 5:\n",
    "        rows.append({'item_type': new_list[0][0], 'content': new_list[0][2]})\n",
    "\n",
    "new_df = pd.DataFrame(rows)\n",
    "\n",
    "new_df['content']=new_df['content'].str.lower()\n",
    "new_df['item_type']=new_df['item_type'].str.lower()\n",
    "\n",
    "train_size = int(new_df.shape[0]*0.8)\n",
    "train_new_df = new_df[:train_size]\n",
    "val_df = new_df[train_size:]  \n",
    "\n",
    "item_type_dict = {item_typ: i for i, item_typ in enumerate(new_df['item_type'].unique())}\n",
    "new_df['item_type_id'] = new_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(new_df['content'])\n",
    "sequences = tokenizer.texts_to_sequences(new_df['content'])\n",
    "\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "labels = to_categorical(new_df['item_type_id'])\n",
    "\n",
    "# Define the model architecture\n",
    "embedding_dim = 50\n",
    "\n",
    "content_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length)\n",
    "embedded_sequences = embedding_layer(content_input)\n",
    "lstm_layer = LSTM(50)(embedded_sequences)\n",
    "\n",
    "dense_layer = Dense(10, activation='relu')(lstm_layer)\n",
    "output_layer = Dense(len(item_type_dict), activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=content_input, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(padded_sequences, labels, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f265cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  1614     0     0     0     0     0]\n",
      " [    0 16105     0     0     0     0     0]\n",
      " [    0  8414     0     0     0     0     0]\n",
      " [    0  1601     0     0     0     0     0]\n",
      " [    0   431     0     0     0     0     0]\n",
      " [    0    40     0     0     0     0     0]\n",
      " [    0     1     0     0     0     0     0]]\n",
      "Class names: ['conditional', 'codelist', 'question', 'statement', 'instruction', 'loop', '']\n"
     ]
    }
   ],
   "source": [
    "# LSTM without NER confusion matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "val_df['item_type_id'] = val_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "# Get the predicted labels for the validation set\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df['content'])\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "y_pred = np.argmax(model.predict(val_padded_sequences), axis=-1)\n",
    "\n",
    "# Get the true labels for the validation set\n",
    "y_true = val_df['item_type_id']\n",
    "\n",
    "# Print the confusion matrix\n",
    "class_names = list(item_type_dict.keys())\n",
    "print(confusion_matrix(y_true, y_pred, labels=list(item_type_dict.values())))\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abfafce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " conditional       0.98      0.98      0.98      1614\n",
      "    codelist       1.00      0.99      1.00     16105\n",
      "    question       0.96      0.97      0.96      8414\n",
      "   statement       0.83      0.76      0.79      1601\n",
      " instruction       0.68      0.78      0.73       431\n",
      "        loop       0.54      0.93      0.68        40\n",
      "                   0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97     28206\n",
      "   macro avg       0.71      0.77      0.73     28206\n",
      "weighted avg       0.97      0.97      0.97     28206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels and ground truth labels for the validation set\n",
    "val_padded_sequences = padded_sequences[int(len(padded_sequences)*0.8):]\n",
    "val_labels = labels[int(len(labels)*0.8):]\n",
    "\n",
    "val_pred_probs = model.predict(val_padded_sequences)\n",
    "val_pred_labels = val_pred_probs.argmax(axis=1)\n",
    "val_true_labels = val_labels.argmax(axis=1)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "report = classification_report(val_true_labels, val_pred_labels, target_names=item_type_dict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "832a05e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " conditional       0.00      0.00      0.00      1614\n",
      "    codelist       0.57      1.00      0.73     16105\n",
      "    question       0.00      0.00      0.00      8414\n",
      "   statement       0.00      0.00      0.00      1601\n",
      " instruction       0.00      0.00      0.00       431\n",
      "        loop       0.00      0.00      0.00        40\n",
      "                   0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57     28206\n",
      "   macro avg       0.08      0.14      0.10     28206\n",
      "weighted avg       0.33      0.57      0.42     28206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Compute evaluation metrics\n",
    "report = classification_report(val_true_labels, val_pred_labels, target_names=item_type_dict.keys())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dde128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " conditional       0.54      0.03      0.05      8031\n",
      "    codelist       0.86      0.92      0.89     83866\n",
      "    question       0.71      0.91      0.80     38974\n",
      "   statement       0.57      0.00      0.01      7024\n",
      " instruction       0.00      0.00      0.00      2823\n",
      "        loop       0.00      0.00      0.00       304\n",
      "                   0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.80    141027\n",
      "   macro avg       0.38      0.27      0.25    141027\n",
      "weighted avg       0.76      0.80      0.75    141027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = new_df['item_type_id']\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = model.predict([padded_sequences, padded_label_sequences])\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# Get the class names\n",
    "class_names = list(item_type_dict.keys())\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM without NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac7d596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     data\n",
      "0       item_type\\titem_urn\\tcontent\\tinstrument_name\\...\n",
      "1       conditional\\turn:ddi:uk.lha:bc358498-7085-4422...\n",
      "2       conditional\\turn:ddi:uk.lha:b7ec8f60-a0b7-4dbb...\n",
      "3       codelist\\turn:ddi:uk.lha:bdb9ae15-1848-41d7-8e...\n",
      "4       codelist\\turn:ddi:uk.lha:5fc4c7c5-2713-4d76-80...\n",
      "...                                                   ...\n",
      "186255  statement\\turn:ddi:uk.lha:7817cb4c-99da-4676-a...\n",
      "186256  instruction\\turn:ddi:uk.lha:ba7dfd64-72ff-4988...\n",
      "186257  instruction\\turn:ddi:uk.lha:c93e8e55-26d3-474f...\n",
      "186258  instruction\\turn:ddi:uk.lha:ebf4e882-9fac-4a72...\n",
      "186259  instruction\\turn:ddi:uk.lha:ff7a6892-04af-4c41...\n",
      "\n",
      "[186260 rows x 1 columns]\n",
      "          item_type                                            content\n",
      "0       conditional  and then go straight on to Question 8]qc_1_i =...\n",
      "1       conditional                         \"[If \"\"YES\"\"]qc_21_a == 1\"\n",
      "2          codelist                                   1 a club at work\n",
      "3          codelist                           2 an outside sports club\n",
      "4          codelist                             3 you and your friends\n",
      "...             ...                                                ...\n",
      "141022    statement  (N.B. By friends we mean people who you meet o...\n",
      "141023  instruction                Please tick the appropriate column.\n",
      "141024  instruction               (PLEASE TICK THE APPROPRIATE COLUMN)\n",
      "141025  instruction         (Circle more than one number if necessary)\n",
      "141026  instruction         (If necessary circle more than one number)\n",
      "\n",
      "[141027 rows x 2 columns]\n",
      "Epoch 1/2\n",
      "3526/3526 [==============================] - 476s 134ms/step - loss: 0.3121 - accuracy: 0.9076 - val_loss: 0.1133 - val_accuracy: 0.9664\n",
      "Epoch 2/2\n",
      "3526/3526 [==============================] - 533s 151ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 0.1054 - val_accuracy: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225784b70c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Input, Bidirectional, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Load the Excel file and read the first sheet into a DataFrame\n",
    "df = pd.read_excel(r'Dataset.xlsx', sheet_name=0, usecols='A:E', header=None)\n",
    "\n",
    "# Concatenate all the columns into a single column\n",
    "df = pd.DataFrame(df.apply(lambda x: ''.join(x.dropna().astype(str)), axis=1))\n",
    "\n",
    "first_col = df.columns[0]\n",
    "df.rename(columns={first_col: 'data'}, inplace=True)\n",
    "print(df)\n",
    "\n",
    "rows = []\n",
    "for index, row in df.iloc[1:].iterrows():\n",
    "    words = re.split(r\"\\s{2,}\", row[0])\n",
    "    new_list = [item.split('\\t') for item in words]\n",
    "    if len(new_list[0]) == 5:\n",
    "        rows.append({'item_type': new_list[0][0], 'content': new_list[0][2]})\n",
    "\n",
    "new_df = pd.DataFrame(rows)\n",
    "print(new_df)\n",
    "\n",
    "new_df['content']=new_df['content'].str.lower()\n",
    "\n",
    "new_df['item_type']=new_df['item_type'].str.lower()\n",
    "\n",
    "train_size = int(new_df.shape[0]*0.8)\n",
    "train_new_df = new_df[:train_size]\n",
    "val_df = new_df[train_size:]  \n",
    "\n",
    "item_type_dict = {item_typ: i for i, item_typ in enumerate(new_df['item_type'].unique())}\n",
    "new_df['item_type_id'] = new_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(new_df['content'])\n",
    "sequences = tokenizer.texts_to_sequences(new_df['content'])\n",
    "\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "labels = to_categorical(new_df['item_type_id'])\n",
    "\n",
    "content_input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_length)(content_input)\n",
    "lstm_layer = Bidirectional(LSTM(50))(embedding_layer)\n",
    "\n",
    "dense_layer = Dense(10, activation='relu')(lstm_layer)\n",
    "output_layer = Dense(len(item_type_dict), activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=content_input, outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(padded_sequences, labels, epochs=2, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b93be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "val_df['item_type_id'] = val_df['item_type'].apply(lambda x: item_type_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b8cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 1559     0    10    20    25     0     0]\n",
      " [    0 15984    67    38    16     0     0]\n",
      " [    1     7  8167   145    92     2     0]\n",
      " [   19    29   339  1147    67     0     0]\n",
      " [    5     1    43    32   349     1     0]\n",
      " [    0     2     5     2     0    31     0]\n",
      " [    1     0     0     0     0     0     0]]\n",
      "Class names: ['conditional', 'codelist', 'question', 'statement', 'instruction', 'loop', '']\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(val_padded_sequences)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "class_names = list(item_type_dict.keys())\n",
    "true_labels = val_df['item_type_id']\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=list(item_type_dict.values()))\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1aba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation data\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df['content'])\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "val_labels = to_categorical(val_df['item_type_id'])\n",
    "y_pred = model.predict(val_padded_sequences)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(val_labels, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b2d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muaaz\\anaconda3\\envs\\mfyp\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882/882 [==============================] - 25s 29ms/step - loss: 0.0319 - accuracy: 0.9908\n",
      "Validation loss: 0.031851109117269516\n",
      "Validation accuracy: 0.9908175468444824\n"
     ]
    }
   ],
   "source": [
    "val_df['item_type_id'] = val_df['item_type'].apply(lambda x: item_type_dict[x])\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df['content'])\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "val_labels = to_categorical(val_df['item_type_id'])\n",
    "\n",
    "loss, accuracy = model.evaluate(val_padded_sequences, val_labels)\n",
    "print(\"Validation loss:\", loss)\n",
    "print(\"Validation accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
